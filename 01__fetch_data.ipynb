{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17b6hdPYYwaw"
   },
   "source": [
    "New York Institute of Technology<br>\n",
    "Course: DTSC 870 / Spring 2022<br>\n",
    "Advisor: Dr. Cao<br>\n",
    "Team: Michael Trzaskoma, Hui (Henry) Chen\n",
    "\n",
    "----\n",
    "\n",
    "This notebook is meant to fetch all necessary dataset for the project. Therefore, this is part of Phase I of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-07T15:23:45.575Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hHgVP-9fAV6",
    "outputId": "9c3c638f-f311-4cb2-ada2-b37785b5616e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # setup to see the execution time in each cell\n",
    "\n",
    "# # !pip install ipython-autotime\n",
    "# !conda install -c conda-forge ipython-autotime -y\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLnjg3bPal-w"
   },
   "source": [
    "# Mount the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hvFJpqwYsV5",
    "outputId": "014db8e8-6f1b-4f29-8d32-0192ed2b6e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "time: 1.14 s (started: 2022-02-06 03:11:37 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5FPNSSnavZh"
   },
   "source": [
    "Now, let's see what's the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5o-uUOFhaqfj",
    "outputId": "89eeb907-8f64-4910-9bbe-49c85dad7077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hui/Projects/dtsc870\n",
      "time: 545 ¬µs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6E-ZJfgfnvG"
   },
   "source": [
    "## Change dataset dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-GRPQ-Ja00I",
    "outputId": "60aa537f-86ab-4d64-cdd6-0cd3b4771912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory is: /home/hui/Projects/dtsc870\n",
      "time: 988 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# feel free to change the dataset to your desired directory:\n",
    "\n",
    "# ROOT_DIR = \"/content/drive/MyDrive/Spring 2022/DTSC 870/Code\"\n",
    "# ROOT_DIR = \"/content/drive/MyDrive/Spring 2022/DTSC 870/Code\"\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "DATASET_DIR = ROOT_DIR + \"/datasets\"\n",
    "# DATASET_DIR = \"/content/drive/MyDrive/Spring 2022/DTSC 870/Code/datasets\"\n",
    "\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "print(\"Current directory is: {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY76Q458fzMn"
   },
   "source": [
    "List of all files under current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0hj43KGgJWI",
    "outputId": "48c704fa-7f16-483f-ed05-a42f3ccdacb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: directory_structure in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from directory_structure) (1.6.3)\n",
      "time: 2.52 s (started: 2022-02-06 03:11:52 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# !pip install directory_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiOBjT9RgXQH",
    "outputId": "5c1efde5-4a9c-4218-9304-93098961b1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Code\n",
      "|_üìÅ datasets\n",
      "|_üìÅ keys\n",
      "|_üìÑ 01__fetch_data.ipynb\n",
      "|_üìÑ 03__MRI_Classifier_a.ipynb\n",
      "|_üìÑ 02__dataset_visualizations.ipynb\n",
      "time: 5.74 ms (started: 2022-02-06 03:11:54 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from directory_structure import Tree\n",
    "\n",
    "print(Tree(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVM9cyD_tjPl"
   },
   "source": [
    "## Create dataset directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfFoexg3tHEa",
    "outputId": "683e6930-3d3c-4a99-c1f9-74e5129af989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 678 ¬µs\n"
     ]
    }
   ],
   "source": [
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "# create the directories if not exist\n",
    "if not os.path.exists(\"./datasets/01_MRI\"):\n",
    "    os.makedirs(\"./datasets/01_MRI\")\n",
    "    os.makedirs(\"./datasets/02_FER\")\n",
    "    os.makedirs(\"./datasets/03_F_MINST\")\n",
    "\n",
    "DATASET_01 = ROOT_DIR + \"/datasets/01_MRI\"\n",
    "DATASET_02 = ROOT_DIR + \"/datasets/02_FER\"\n",
    "DATASET_03 = ROOT_DIR + \"/datasets/03_F_MINST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RES6Ya1MgcUY"
   },
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzzdTwLMt4pr"
   },
   "source": [
    "## Setup\n",
    "\n",
    "The easiest way to download the dataset from the Kaggle would be through the Kaggle API. Ref: https://www.kaggle.com/general/74235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoDYgNn1gpPQ",
    "outputId": "a997a4ae-6939-4ebf-831a-763c95381e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/hui/anaconda3/envs/dtsc870\n",
      "\n",
      "  added / updated specs:\n",
      "    - kaggle\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotlipy-0.7.0             |py310h6acc77f_1003         1.0 MB  conda-forge\n",
      "    certifi-2021.10.8          |  py310hff52083_1         145 KB  conda-forge\n",
      "    cffi-1.15.0                |  py310h0fdd8cc_0         433 KB  conda-forge\n",
      "    charset-normalizer-2.0.11  |     pyhd8ed1ab_0          35 KB  conda-forge\n",
      "    cryptography-36.0.0        |  py310h9ce1e76_0         1.6 MB\n",
      "    idna-3.3                   |     pyhd8ed1ab_0          55 KB  conda-forge\n",
      "    kaggle-1.5.12              |     pyhd8ed1ab_4          53 KB  conda-forge\n",
      "    pyopenssl-22.0.0           |     pyhd8ed1ab_0          49 KB  conda-forge\n",
      "    pysocks-1.7.1              |  py310hff52083_4          28 KB  conda-forge\n",
      "    python-slugify-5.0.2       |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    requests-2.27.1            |     pyhd8ed1ab_0          53 KB  conda-forge\n",
      "    text-unidecode-1.3         |             py_0          68 KB  conda-forge\n",
      "    unidecode-1.3.2            |     pyhd8ed1ab_0         155 KB  conda-forge\n",
      "    urllib3-1.26.8             |     pyhd8ed1ab_1         100 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py310h6acc77f_1003\n",
      "  certifi            conda-forge/linux-64::certifi-2021.10.8-py310hff52083_1\n",
      "  cffi               conda-forge/linux-64::cffi-1.15.0-py310h0fdd8cc_0\n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-2.0.11-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py310h9ce1e76_0\n",
      "  idna               conda-forge/noarch::idna-3.3-pyhd8ed1ab_0\n",
      "  kaggle             conda-forge/noarch::kaggle-1.5.12-pyhd8ed1ab_4\n",
      "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0\n",
      "  pyopenssl          conda-forge/noarch::pyopenssl-22.0.0-pyhd8ed1ab_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-py310hff52083_4\n",
      "  python-slugify     conda-forge/noarch::python-slugify-5.0.2-pyhd8ed1ab_0\n",
      "  requests           conda-forge/noarch::requests-2.27.1-pyhd8ed1ab_0\n",
      "  text-unidecode     conda-forge/noarch::text-unidecode-1.3-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.62.3-pyhd8ed1ab_0\n",
      "  unidecode          conda-forge/noarch::unidecode-1.3.2-pyhd8ed1ab_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.8-pyhd8ed1ab_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "brotlipy-0.7.0       | 1.0 MB    | ##################################### | 100% \n",
      "idna-3.3             | 55 KB     | ##################################### | 100% \n",
      "cffi-1.15.0          | 433 KB    | ##################################### | 100% \n",
      "text-unidecode-1.3   | 68 KB     | ##################################### | 100% \n",
      "requests-2.27.1      | 53 KB     | ##################################### | 100% \n",
      "python-slugify-5.0.2 | 12 KB     | ##################################### | 100% \n",
      "pyopenssl-22.0.0     | 49 KB     | ##################################### | 100% \n",
      "kaggle-1.5.12        | 53 KB     | ##################################### | 100% \n",
      "charset-normalizer-2 | 35 KB     | ##################################### | 100% \n",
      "pysocks-1.7.1        | 28 KB     | ##################################### | 100% \n",
      "unidecode-1.3.2      | 155 KB    | ##################################### | 100% \n",
      "urllib3-1.26.8       | 100 KB    | ##################################### | 100% \n",
      "cryptography-36.0.0  | 1.6 MB    | ##################################### | 100% \n",
      "certifi-2021.10.8    | 145 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "time: 9.31 s\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q \n",
    "# !conda install -c conda-forge kaggle -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLPgNGWIiwo0",
    "outputId": "6430456f-2262-4d36-f58b-012382eebd16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hui/Projects/dtsc870/keys/kaggle.json\n",
      "time: 610 ¬µs\n"
     ]
    }
   ],
   "source": [
    "KAGGLE_KEY = ROOT_DIR + \"/keys/kaggle.json\"\n",
    "print(KAGGLE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9GmDuLp8iO"
   },
   "source": [
    "Create a kaggle environment and then copy the kaggle key to that directory. Lastly, modify the key's permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNrEiW6yiqxZ",
    "outputId": "9f5bec05-ffcb-4c80-c987-fd7394c2fb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "\n",
    "# # !cp /content/drive/MyDrive/'Spring 2022'/'DTSC 870'/Code/keys/kaggle.json ~/.kaggle/\n",
    "# !cp /home/hui/Projects/dtsc870/keys/kaggle.json ~/.kaggle/\n",
    "\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFKLFVDaqPYe"
   },
   "source": [
    "Output a list of dataset to test if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4yVEBNUmZCI",
    "outputId": "86eb861a-6664-46b1-fd39-1766e0f43caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                         title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "nkitgupta/jigsaw-regression-based-data                      Jigsaw Regression Based Data                         3GB  2022-02-05 20:51:56            829         78  0.88235295       \n",
      "prasertk/netflix-subscription-price-in-different-countries  Netflix subscription fee in different countries      3KB  2022-01-15 07:06:09           2255         68  1.0              \n",
      "yasserh/wine-quality-dataset                                Wine Quality Dataset                                21KB  2022-01-15 19:15:11           2002         79  1.0              \n",
      "yamqwe/netflix-showse                                       Netflix Shows                                       11KB  2022-01-23 00:03:01           1329         46  1.0              \n",
      "sanjeetsinghnaik/top-1000-highest-grossing-movies           Top 1000 Highest Grossing Movies                   106KB  2022-01-15 16:26:14           1456         68  1.0              \n",
      "iamsouravbanerjee/analytics-industry-salaries-2022-india    Data Professionals Salary - 2022                    57KB  2022-02-04 09:04:46           2446         83  1.0              \n",
      "majyhain/height-of-male-and-female-by-country-2022          Height of Male and Female by Country 2022            4KB  2022-02-02 00:40:19            448         32  1.0              \n",
      "majyhain/top-100-cryptocurrency-2022                        Top 100 Cryptocurrency 2022                          4KB  2022-01-31 09:23:53            313         31  0.9411765        \n",
      "yamqwe/shark-tank-companiese                                üì± Shark Tank Companies                              70KB  2022-01-30 21:01:58            444         21  1.0              \n",
      "kenjee/ken-jee-youtube-data                                 Ken Jee YouTube Data                                 6MB  2022-01-22 20:38:53            143         71  1.0              \n",
      "yamqwe/men-s-shoe-pricese                                   ü©∞ Men's Shoe Prices                                  6MB  2022-01-24 15:19:48            598         31  1.0              \n",
      "yamqwe/omicron-covid19-variant-daily-cases                  Omicron daily cases by country (COVID-19 variant)     0B  2022-02-07 14:02:21          14245        629  1.0              \n",
      "meetnagadia/netflix-stock-price-data-set-20022022           Netflix Stock Price Data set 2002-2022              94KB  2022-01-12 05:28:11            747         22  1.0              \n",
      "dansbecker/melbourne-housing-snapshot                       Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24          80126        987  0.7058824        \n",
      "datasnaek/youtube-new                                       Trending YouTube Video Statistics                  201MB  2019-06-03 00:56:47         165059       4407  0.7941176        \n",
      "yamqwe/air-traffic-passenger-datae                          üåÅ Air Traffic Passenger Data                       173KB  2022-01-29 14:08:10            459         17  1.0              \n",
      "vivovinco/nba-player-stats                                  2021-2022 NBA Player Stats                          29KB  2022-01-22 14:53:22            474         21  1.0              \n",
      "maricinnamon/harry-potter-movies-dataset                    Harry Potter Movies Dataset                        211KB  2022-01-14 10:13:19            396         21  1.0              \n",
      "zynicide/wine-reviews                                       Wine Reviews                                        51MB  2017-11-27 17:08:04         153746       3255  0.7941176        \n",
      "datasnaek/chess                                             Chess Game Dataset (Lichess)                         3MB  2017-09-04 03:09:09          27467        943  0.8235294        \n",
      "time: 613 ms\n"
     ]
    }
   ],
   "source": [
    "# !kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzkBUE_M05N6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVHq8mrjxPwE"
   },
   "source": [
    "We want to split the Normal and Tumor into train and test set with ratio of 0.7:0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJLUwRYrxJsw",
    "outputId": "d21ea2b7-e924-4cc6-b632-dc3207404ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 400 ¬µs\n"
     ]
    }
   ],
   "source": [
    "TRAIN_K = 0.7\n",
    "TEST_K = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w4LsjVWuQY0"
   },
   "source": [
    "## Utility Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZG7dC3-5the",
    "outputId": "8f5ae8a0-b465-47e5-b576-a93330a6668f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 439 ¬µs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_train_test_dir(sub_dir, class_):\n",
    "  # sub_dir : train/test\n",
    "  # class_ : class label of the dataset\n",
    "  # print(os.getcwd())\n",
    "  # dir = dataset_dir + sub_dir + \"/\" + class_\n",
    "  dir = os.getcwd() + sub_dir + \"/\" + class_\n",
    "  os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3UGFf4MuVkc",
    "outputId": "56157308-4aa7-42ba-ba3d-6bcb9cea67df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def set_move(sub_dir, target):\n",
    "    # os.chdir(sub_dir)\n",
    "    \n",
    "    print(\"The sample size is: {}\".format(target[\"k\"]))\n",
    "    \n",
    "    for c in random.sample(glob.glob('*'), target[\"k\"]):\n",
    "        print(f\"\\nC is: {c}\\n\\n\")\n",
    "        shutil.copy(c, os.getcwd()+target[\"dir\"]+ \"/\" +sub_dir)\n",
    "    \n",
    "    print(\"All operations are done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxAD7K22giW8"
   },
   "source": [
    "## MRI Based Brain Tumor Images\n",
    "\n",
    "URL: https://www.kaggle.com/mhantor/mri-based-brain-tumor-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3fLbd-IqYEN",
    "outputId": "122484b6-03de-458c-ebcf-d4b297b0f883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hui/Projects/dtsc870/datasets/01_MRI\n",
      "time: 415 ¬µs\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DATASET_01)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAV_29jaolHI"
   },
   "source": [
    "In order to download and unzip the dataset from a competition, we need to provide the URL of the dataset along with the following command line:\n",
    "\n",
    "```\n",
    "!kaggle datasets download <URL suffix: everything afer \"kaggle.com/\"> -p <desired directory to save the dataset> --unzip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ny91S7WdsxLP",
    "outputId": "e7e3d9f5-47ab-4610-d0b7-b3790331d5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hui/Projects/dtsc870/datasets/01_MRI\n",
      "time: 342 ¬µs\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAQ3tks_mc8P",
    "outputId": "2351b0c9-c5f5-4bfd-f57f-b3e9f62c9525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mri-based-brain-tumor-images.zip to /home/hui/Projects/dtsc870/datasets/01_MRI\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.99M/8.99M [00:00<00:00, 12.0MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.99M/8.99M [00:00<00:00, 10.8MB/s]\n",
      "time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions download -c 'MRI-Based-Brain-Tumor-Images'\n",
    "\n",
    "# !kaggle datasets download mhantor/mri-based-brain-tumor-images/download -p /content/drive/MyDrive/'Spring 2022'/'DTSC 870'/Code/datasets/01_MRI --unzip\n",
    "!kaggle datasets download mhantor/mri-based-brain-tumor-images/download -p /home/hui/Projects/dtsc870/datasets/01_MRI --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFaSRjGuue4V"
   },
   "source": [
    "Now let's see if we have downloaded all MRI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtVrUjtMuks4",
    "outputId": "b4d7956b-7c3d-469d-f25c-876b8b1c2841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hui/Projects/dtsc870\n",
      "time: 955 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# modify the directory for var 'DATASET_01'\n",
    "DATASET_01 = DATASET_01 + \"/Brain_tumor_images\"\n",
    "\n",
    "# os.chdir(\"./Brain_tumor_images\")\n",
    "print((os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7oBBvZTuo0l"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.getcwd() + \"/Brain_tumor_images/Normal\")\n",
    "print(Tree(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dS4megBWuz82"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../Tumor\")\n",
    "print(Tree(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sc3PPmAfr9df"
   },
   "source": [
    "### Generate the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiZU35hLrHhb",
    "outputId": "26d40477-c930-45b2-9adf-db4bdb62a168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tumor img: 230\n",
      "# of normal img: 170\n",
      "List of class in MRI image data: ['Tumor', 'Normal']\n",
      "time: 2.16 ms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import glob\n",
    "\n",
    "# get the length of tumor and normal\n",
    "tumor_len = len([file for file in os.scandir(DATASET_01+\"/Tumor\")])\n",
    "normal_len = len([file for file in os.scandir(DATASET_01+\"/Normal\")])\n",
    "\n",
    "# get a list class in MRI img data\n",
    "os.chdir(DATASET_01)\n",
    "mri_classes = [file for file in os.listdir(os.getcwd())]\n",
    "\n",
    "print(f\"# of tumor img: {tumor_len}\")\n",
    "print(f\"# of normal img: {normal_len}\")\n",
    "print(f\"List of class in MRI image data: {mri_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOy1c33uEVSa",
    "outputId": "89ece4cb-8b13-4958-87a5-c94874c17052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.63 ms\n"
     ]
    }
   ],
   "source": [
    "# create the train and test directories with class labels\n",
    "\n",
    "dirs = [\"/train\", \"/test\"]\n",
    "\n",
    "for c in mri_classes:\n",
    "  for tar_k in dirs:\n",
    "    # check the current dir back to MRI dataset\n",
    "    os.chdir(DATASET_01)\n",
    "    # print(os.getcwd())\n",
    "    # print(f\"For class: {c} and target: {tar_k}\")\n",
    "    create_train_test_dir(tar_k, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "7jYm5vtc07g6",
    "outputId": "17592c61-e1d2-4682-d74b-7a622406c23b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class: 'Tumor' and target: {'k': 161, 'dir': '/train'}\n",
      "The sample size is: 161\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(os.getcwd())\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor class: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtar_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mset_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_k\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mset_move\u001b[0;34m(sub_dir, target)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_move\u001b[39m(sub_dir, target):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# os.chdir(sub_dir)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sample size is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mC is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mmove(c, os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39mtarget[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdir\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39msub_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/dtsc870/lib/python3.10/random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    480\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    484\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.4 ms\n"
     ]
    }
   ],
   "source": [
    "tumor_k = [{\"k\": round(tumor_len*TRAIN_K), \"dir\": \"/train\"}, {\"k\": round(tumor_len*TEST_K), \"dir\": \"/test\"}]\n",
    "normal_k = [{\"k\": round(normal_len*TRAIN_K), \"dir\": \"/train\"}, {\"k\": round(normal_len*TEST_K), \"dir\": \"/test\"}]\n",
    "\n",
    "for c in mri_classes:\n",
    "\n",
    "  # since tumor and normal have different sample size, \n",
    "  # we need to seprating specify the train and test split ratio\n",
    "  target = tumor_k\n",
    "  if str(c) == \"Normal\":\n",
    "    target = normal_k\n",
    "\n",
    "  for tar_k in target:\n",
    "    # check the current dir back to MRI dataset\n",
    "    os.chdir(DATASET_01)\n",
    "    # print(os.getcwd())\n",
    "    print(f\"For class: '{c}' and target: {tar_k}\")\n",
    "    set_move(c, tar_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_rRpBGnv-y7"
   },
   "source": [
    "## FER-2013\n",
    "\n",
    "URL: https://www.kaggle.com/msambare/fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1btVuM1vyQX"
   },
   "outputs": [],
   "source": [
    "os.chdir(DATASET_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA4UqNB8wf8Z"
   },
   "source": [
    "Downloading the dataset.\n",
    "\n",
    "**Note: this process will take long as there are many images to unzip from the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1t6SpmMwWWr",
    "outputId": "0a744499-72ad-4afd-db9f-32b3161b84bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fer2013.zip to /content/drive/MyDrive/Spring 2022/DTSC 870/Code/datasets/02_FER\n",
      " 80% 48.0M/60.3M [00:00<00:00, 58.3MB/s]\n",
      "100% 60.3M/60.3M [00:00<00:00, 102MB/s] \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download msambare/fer2013/download -p /content/drive/MyDrive/'Spring 2022'/'DTSC 870'/Code/datasets/02_FER --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Nc-CyiUwxYZ",
    "outputId": "0f054d26-27e9-42ca-e95d-e26b757c0e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ train\n",
      "|_üìÅ angry\n",
      "|_üìÅ disgust\n",
      "|_üìÅ fear\n",
      "|_üìÅ happy\n",
      "|_üìÅ neutral\n",
      "|_üìÅ sad\n",
      "|_üìÅ surprise\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DATASET_02 + \"/train\")\n",
    "print(Tree(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9eUycS9yJxp"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./angry\")\n",
    "print(Tree(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcPWMDX0ycZr"
   },
   "source": [
    "## Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1XYCrN0zX-f"
   },
   "source": [
    "For the Fashion-MNIST dataset, we can retrieve it through TensorFlow:\n",
    "\n",
    "```\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "(images, labels), (_,_) = load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOq6y9Z-zlhp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01__fetch_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "dtsc870",
   "language": "python",
   "name": "dtsc870"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
